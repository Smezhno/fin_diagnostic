# RFC: –§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è SMB (v3)

## –û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞

**–ù–∞–∑–≤–∞–Ω–∏–µ:** FinRentgen (—Ä–∞–±–æ—á–µ–µ)

**–¶–µ–ª—å:** –í–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞ –∏ –≤—ã–¥–∞—ë—Ç actionable –∏–Ω—Å–∞–π—Ç—ã.

**–¶–µ–ª–µ–≤–æ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:** –ò–ü/–≤–ª–∞–¥–µ–ª–µ—Ü –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞ –≤ –†–æ—Å—Å–∏–∏ —Å –æ–±–æ—Ä–æ—Ç–æ–º 500–ö-5–ú‚ÇΩ/–º–µ—Å, –±–µ–∑ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞.

**–°—Ç–∞–¥–∏—è:** –ü—Ä–æ—Ç–æ—Ç–∏–ø –¥–ª—è customer development –∏–Ω—Ç–µ—Ä–≤—å—é.

---

## –í–æ–ª–Ω—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

### üåä Wave 1: Ultra-MVP (10-15 —á–∞—Å–æ–≤)

**–¶–µ–ª—å:** –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç –¥–ª—è –ø–µ—Ä–≤—ã—Ö 5-10 –∫–∞—Å—Ç–¥–µ–≤-–∏–Ω—Ç–µ—Ä–≤—å—é.

**–í–∫–ª—é—á–∞–µ—Ç:**
- ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ (CSV, Excel)
- ‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≥—Ä—è–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–π —Ä–∞—Å—á—ë—Ç –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
- ‚úÖ –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ OpenAI (–æ–¥–∏–Ω –ø—Ä–æ–≤–∞–π–¥–µ—Ä)
- ‚úÖ –í—ã–≤–æ–¥ –∏–Ω—Å–∞–π—Ç–æ–≤ + –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- ‚úÖ –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏—è—Ç–Ω—ã–π UI

**–ù–ï –≤–∫–ª—é—á–∞–µ—Ç:**
- ‚ùå –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
- ‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
- ‚ùå –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–π
- ‚ùå –ß–∞—Ç
- ‚ùå –°—Ü–µ–Ω–∞—Ä–∏–∏ "—á—Ç–æ –µ—Å–ª–∏"
- ‚ùå –ú—É–ª—å—Ç–∏-LLM

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ú–æ–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –ª—é–¥—è–º, —Å–æ–±—Ä–∞—Ç—å —Ñ–∏–¥–±–µ–∫, –ø–æ–Ω—è—Ç—å —á—Ç–æ –≤–∞–∂–Ω–æ.

---

### üåä Wave 2: MVP+ (–ø–æ—Å–ª–µ 5-10 –∏–Ω—Ç–µ—Ä–≤—å—é)

**–î–æ–±–∞–≤–ª—è–µ—Ç—Å—è –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∫–∞—Å—Ç–¥–µ–≤–æ–≤:**
- –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (email + –ø–∞—Ä–æ–ª—å)
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–π –≤ SQLite
- –ò—Å—Ç–æ—Ä–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤
- –ß–∞—Ç —Å —É—Ç–æ—á–Ω–µ–Ω–∏—è–º–∏
- –°—Ü–µ–Ω–∞—Ä–∏–∏ "—á—Ç–æ –µ—Å–ª–∏"
- YandexGPT / GigaChat

**–†–µ—à–µ–Ω–∏–µ –æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞—Ö ‚Äî –ø–æ—Å–ª–µ Wave 1.**

---

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Wave 1

### –ü—Ä–∏–Ω—Ü–∏–ø—ã

1. **–ú–µ—Ç—Ä–∏–∫–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ** ‚Äî LLM —Ç–æ–ª—å–∫–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç –≥–æ—Ç–æ–≤—ã–µ —Ü–∏—Ñ—Ä—ã
2. **–ì—Ä—è–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ‚Äî –Ω–æ—Ä–º–∞** ‚Äî –ø–∞—Ä—Å–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–µ–∞–ª—å–Ω—ã–º Excel
3. **JSON –º–æ–∂–µ—Ç —Å–ª–æ–º–∞—Ç—å—Å—è** ‚Äî –µ—Å—Ç—å repair-–º–µ—Ö–∞–Ω–∏–∫–∞
4. **–ß–µ—Å—Ç–Ω–æ–µ –≤—Ä–µ–º—è** ‚Äî "–¥–æ 30 —Å–µ–∫—É–Ω–¥" –≤–º–µ—Å—Ç–æ –æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã—Ö 15
5. **AI-–∞–≥–Ω–æ—Å—Ç–∏—á–Ω–æ—Å—Ç—å** ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –∑–∞–≤—è–∑–∞–Ω–∞ –∂—ë—Å—Ç–∫–æ –Ω–∞ OpenAI. –í Wave 1 –æ–¥–∏–Ω –∫–ª–∏–µ–Ω—Ç, –Ω–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–æ–µ–∫—Ç–∏—Ä—É–µ—Ç—Å—è –ø–æ–¥ future-–º—É–ª—å—Ç–∏-LLM (YandexGPT, GigaChat –∏ –¥—Ä.)

---

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (Wave 1)

```
fin-analyzer/
‚îú‚îÄ‚îÄ app.py                  # –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞, Gradio UI
‚îú‚îÄ‚îÄ config.py               # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ .env.example
‚îÇ
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py         # –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞
‚îÇ   ‚îî‚îÄ‚îÄ metrics.py          # –í–°–ï —Ä–∞—Å—á—ë—Ç—ã –º–µ—Ç—Ä–∏–∫ (–ª–æ–∫–∞–ª—å–Ω–æ)
‚îÇ
‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ client.py           # OpenAI –∫–ª–∏–µ–Ω—Ç
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py          # –ü—Ä–æ–º–ø—Ç—ã
‚îÇ   ‚îî‚îÄ‚îÄ response_parser.py  # –ü–∞—Ä—Å–∏–Ω–≥ + repair JSON
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ parser.py           # –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ + –æ—á–∏—Å—Ç–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ cleaner.py          # –û—á–∏—Å—Ç–∫–∞ –≥—Ä—è–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îî‚îÄ‚îÄ models.py           # Pydantic –º–æ–¥–µ–ª–∏
‚îÇ
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ components.py       # Gradio –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
‚îÇ   ‚îî‚îÄ‚îÄ styles.py           # CSS (ClickUp-like)
‚îÇ
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ sample_pnl_clean.csv
‚îÇ   ‚îî‚îÄ‚îÄ sample_pnl_dirty.csv  # –° —Ä–µ–∞–ª—å–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏
‚îÇ
‚îî‚îÄ‚îÄ requirements.txt
```

---

## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (config.py)

```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    app_name: str = "FinRentgen"
    debug: bool = False
    
    # LLM (Wave 1: —Ç–æ–ª—å–∫–æ OpenAI)
    openai_api_key: str
    openai_model: str = "gpt-4o"
    
    # –õ–∏–º–∏—Ç—ã
    max_file_size_mb: int = 5
    max_rows: int = 100
    min_periods: int = 3
    
    # LLM retry
    llm_max_retries: int = 2
    llm_timeout_seconds: int = 60
    
    class Config:
        env_file = ".env"

settings = Settings()
```

---

## –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö (data/models.py)

```python
from pydantic import BaseModel, Field, field_validator
from datetime import date
from enum import Enum
from typing import Optional

class InsightType(str, Enum):
    PROBLEM = "problem"          # üî¥
    OBSERVATION = "observation"  # üü°
    OPPORTUNITY = "opportunity"  # üü¢

class TrendDirection(str, Enum):
    GROWING = "growing"
    STABLE = "stable"
    DECLINING = "declining"
    INSUFFICIENT_DATA = "insufficient_data"

class PnLRow(BaseModel):
    """–û–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ P&L (–æ–¥–∏–Ω –ø–µ—Ä–∏–æ–¥)"""
    period: date
    revenue: float = Field(..., gt=0, description="–í—ã—Ä—É—á–∫–∞")
    cogs: Optional[float] = Field(None, ge=0, description="–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å")
    rent: Optional[float] = Field(None, ge=0, description="–ê—Ä–µ–Ω–¥–∞")
    payroll: Optional[float] = Field(None, ge=0, description="–§–û–¢")
    marketing: Optional[float] = Field(None, ge=0, description="–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥")
    other_expenses: Optional[float] = Field(None, ge=0, description="–ü—Ä–æ—á–∏–µ")

class PnLData(BaseModel):
    """–ü–æ–ª–Ω—ã–π P&L"""
    rows: list[PnLRow]
    business_context: Optional[str] = None
    parsing_warnings: list[str] = Field(default_factory=list)  # –ß—Ç–æ –±—ã–ª–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ

class CalculatedMetrics(BaseModel):
    """–ú–µ—Ç—Ä–∏–∫–∏, –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –õ–û–ö–ê–õ–¨–ù–û (–Ω–µ LLM)"""
    
    # –°—Ä–µ–¥–Ω–∏–µ –∑–∞ –ø–µ—Ä–∏–æ–¥
    avg_revenue: float
    avg_cogs: Optional[float]
    avg_gross_profit: Optional[float]
    avg_gross_margin_pct: Optional[float]
    avg_operating_profit: float
    avg_operating_margin_pct: float
    
    # –¢—Ä–µ–Ω–¥—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –ø–µ—Ä–∏–æ–¥–∞ vs –ø—Ä–µ–¥—ã–¥—É—â–∏–µ)
    revenue_trend_pct: float  # +10% = —Ä–∞—Å—Ç—ë—Ç
    revenue_trend_direction: TrendDirection
    
    # –î–æ–ª–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤ –æ—Ç –≤—ã—Ä—É—á–∫–∏ (—Å—Ä–µ–¥–Ω–∏–µ)
    cogs_share_pct: Optional[float]
    rent_share_pct: Optional[float]
    payroll_share_pct: Optional[float]
    marketing_share_pct: Optional[float]
    other_share_pct: Optional[float]
    
    # –ê–Ω–æ–º–∞–ª–∏–∏
    anomalies: list[str]  # ["–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥ –≤ –º–∞—Ä—Ç–µ –≤—ã—Ä–æ—Å –Ω–∞ 45%"]
    
    # –ü–æ –ø–µ—Ä–∏–æ–¥–∞–º (–¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è)
    by_period: list[dict]  # [{period, revenue, profit, margin}, ...]

class Insight(BaseModel):
    """–û–¥–∏–Ω –∏–Ω—Å–∞–π—Ç"""
    type: InsightType
    title: str
    explanation: str
    recommendation: str
    potential_impact: Optional[str] = None

class AnalysisResult(BaseModel):
    """–ü–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞"""
    metrics: CalculatedMetrics  # –ü–æ—Å—á–∏—Ç–∞–Ω–æ –ª–æ–∫–∞–ª—å–Ω–æ
    insights: list[Insight]     # –û—Ç LLM
    parsing_warnings: list[str] = Field(default_factory=list)  # –ß—Ç–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
    llm_raw_response: Optional[str] = None  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
```

---

## –õ–æ–∫–∞–ª—å–Ω—ã–π —Ä–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ (core/metrics.py)

```python
"""
–í–°–ï –º–µ—Ç—Ä–∏–∫–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –∑–¥–µ—Å—å, –ª–æ–∫–∞–ª—å–Ω–æ.
LLM –ø–æ–ª—É—á–∞–µ—Ç —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ —Ü–∏—Ñ—Ä—ã –∏ —Ç–æ–ª—å–∫–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç –∏—Ö.
"""

from data.models import PnLData, PnLRow, CalculatedMetrics
from statistics import mean, stdev
from typing import Optional

def calculate_metrics(data: PnLData) -> CalculatedMetrics:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á—ë—Ç–∞ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫"""
    
    rows = data.rows
    n = len(rows)
    
    # === –ë–∞–∑–æ–≤—ã–µ —Å—Ä–µ–¥–Ω–∏–µ ===
    revenues = [r.revenue for r in rows]
    avg_revenue = mean(revenues)
    
    # –°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å –∏ –≤–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å
    cogs_values = [r.cogs for r in rows if r.cogs is not None]
    avg_cogs = mean(cogs_values) if cogs_values else None
    
    if avg_cogs is not None:
        avg_gross_profit = avg_revenue - avg_cogs
        avg_gross_margin_pct = (avg_gross_profit / avg_revenue) * 100
    else:
        avg_gross_profit = None
        avg_gross_margin_pct = None
    
    # –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å
    operating_profits = [_calc_operating_profit(r) for r in rows]
    avg_operating_profit = mean(operating_profits)
    avg_operating_margin_pct = (avg_operating_profit / avg_revenue) * 100
    
    # === –¢—Ä–µ–Ω–¥—ã ===
    revenue_trend_pct, revenue_trend_direction = _calc_trend(revenues)
    
    # === –î–æ–ª–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤ ===
    cogs_share = _avg_share(rows, 'cogs')
    rent_share = _avg_share(rows, 'rent')
    payroll_share = _avg_share(rows, 'payroll')
    marketing_share = _avg_share(rows, 'marketing')
    other_share = _avg_share(rows, 'other_expenses')
    
    # === –ê–Ω–æ–º–∞–ª–∏–∏ ===
    anomalies = _detect_anomalies(rows)
    
    # === –ü–æ –ø–µ—Ä–∏–æ–¥–∞–º (–¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è) ===
    by_period = [
        {
            "period": r.period.isoformat(),
            "revenue": r.revenue,
            "profit": _calc_operating_profit(r),
            "margin_pct": round((_calc_operating_profit(r) / r.revenue) * 100, 1) if r.revenue else None
        }
        for r in rows
    ]
    
    return CalculatedMetrics(
        avg_revenue=round(avg_revenue, 0),
        avg_cogs=round(avg_cogs, 0) if avg_cogs else None,
        avg_gross_profit=round(avg_gross_profit, 0) if avg_gross_profit else None,
        avg_gross_margin_pct=round(avg_gross_margin_pct, 1) if avg_gross_margin_pct else None,
        avg_operating_profit=round(avg_operating_profit, 0),
        avg_operating_margin_pct=round(avg_operating_margin_pct, 1),
        revenue_trend_pct=round(revenue_trend_pct, 1),
        revenue_trend_direction=revenue_trend_direction,
        cogs_share_pct=cogs_share,
        rent_share_pct=rent_share,
        payroll_share_pct=payroll_share,
        marketing_share_pct=marketing_share,
        other_share_pct=other_share,
        anomalies=anomalies,
        by_period=by_period
    )


def _calc_operating_profit(row: PnLRow) -> float:
    """–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–∏–±—ã–ª—å = –≤—ã—Ä—É—á–∫–∞ - –≤—Å–µ —Ä–∞—Å—Ö–æ–¥—ã"""
    # –í–∞–∂–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º `is not None`, –∞ –Ω–µ filter(None), 
    # —á—Ç–æ–±—ã –Ω–µ —Ç–µ—Ä—è—Ç—å –Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    expenses = sum(v for v in [
        row.cogs, row.rent, row.payroll, 
        row.marketing, row.other_expenses
    ] if v is not None)
    return row.revenue - expenses


def _calc_trend(values: list[float]) -> tuple[float, str]:
    """
    –¢—Ä–µ–Ω–¥: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –ø–µ—Ä–∏–æ–¥–∞ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–ø—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ)
    
    –í–ê–ñ–ù–û: –ü—Ä–∏ –º–µ–Ω–µ–µ —á–µ–º 6 –ø–µ—Ä–∏–æ–¥–∞—Ö —Ç—Ä–µ–Ω–¥ –Ω–µ–Ω–∞–¥—ë–∂–µ–Ω.
    """
    # –ú–∏–Ω–∏–º—É–º 6 –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞
    if len(values) < 6:
        return 0.0, "insufficient_data"
    
    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 vs –ø—Ä–µ–¥—ã–¥—É—â–∏–µ 3
    recent = values[-3:]
    previous = values[-6:-3]
    
    avg_recent = mean(recent)
    avg_previous = mean(previous)
    
    if avg_previous == 0:
        return 0.0, "stable"
    
    change_pct = ((avg_recent - avg_previous) / avg_previous) * 100
    
    if change_pct > 5:
        direction = "growing"
    elif change_pct < -5:
        direction = "declining"
    else:
        direction = "stable"
    
    return change_pct, direction


def _avg_share(rows: list[PnLRow], field: str) -> Optional[float]:
    """
    –°—Ä–µ–¥–Ω—è—è –¥–æ–ª—è —Å—Ç–∞—Ç—å–∏ —Ä–∞—Å—Ö–æ–¥–æ–≤ –æ—Ç –≤—ã—Ä—É—á–∫–∏ –ü–û –ü–ï–†–ò–û–î–ê–ú.
    
    –í–∞–∂–Ω–æ: —Å—á–∏—Ç–∞–µ–º –¥–æ–ª—é –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞, –ø–æ—Ç–æ–º —É—Å—Ä–µ–¥–Ω—è–µ–º.
    –≠—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–µ–µ, —á–µ–º (—Å—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Ö–æ–¥–æ–≤ / —Å—Ä–µ–¥–Ω—è—è –≤—ã—Ä—É—á–∫–∞).
    """
    shares = []
    for r in rows:
        val = getattr(r, field)
        if val is not None and r.revenue:
            shares.append(val / r.revenue)
    if not shares:
        return None
    return round(mean(shares) * 100, 1)


def _detect_anomalies(rows: list[PnLRow]) -> list[str]:
    """
    –ü–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π: —Ä–µ–∑–∫–∏–µ —Å–∫–∞—á–∫–∏ (>30%) –º–µ—Å—è—Ü –∫ –º–µ—Å—è—Ü—É.
    """
    anomalies = []
    
    if len(rows) < 2:
        return anomalies
    
    fields = [
        ('revenue', '–í—ã—Ä—É—á–∫–∞'),
        ('cogs', '–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å'),
        ('marketing', '–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥'),
        ('payroll', '–§–û–¢'),
        ('rent', '–ê—Ä–µ–Ω–¥–∞')
    ]
    
    for field, name in fields:
        values = [(r.period, getattr(r, field)) for r in rows]
        values = [(p, v) for p, v in values if v is not None]
        
        for i in range(1, len(values)):
            prev_period, prev_val = values[i-1]
            curr_period, curr_val = values[i]
            
            if prev_val == 0:
                continue
                
            change_pct = ((curr_val - prev_val) / prev_val) * 100
            
            if abs(change_pct) > 30:
                direction = "–≤—ã—Ä–æ—Å" if change_pct > 0 else "—É–ø–∞–ª"
                anomalies.append(
                    f"{name} –≤ {curr_period.strftime('%B %Y')} {direction} –Ω–∞ {abs(change_pct):.0f}%"
                )
    
    return anomalies[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 –∞–Ω–æ–º–∞–ª–∏–π
```

---

## –û—á–∏—Å—Ç–∫–∞ –≥—Ä—è–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (data/cleaner.py)

```python
"""
–†–µ–∞–ª—å–Ω—ã–µ Excel –æ—Ç SMB —Å–æ–¥–µ—Ä–∂–∞—Ç:
- "1 200 000" –∏ "1,200,000"
- "‚Äî", "–Ω–µ—Ç", "-"
- –ü—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
- –ò—Ç–æ–≥–∏ –≤–Ω–∏–∑—É
- –ó–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö
"""

import re
from typing import Optional
import pandas as pd

# –°–∏–Ω–æ–Ω–∏–º—ã –∫–æ–ª–æ–Ω–æ–∫
COLUMN_SYNONYMS = {
    'period': ['–º–µ—Å—è—Ü', '–ø–µ—Ä–∏–æ–¥', 'date', '–¥–∞—Ç–∞', 'month', '–≥–æ–¥/–º–µ—Å—è—Ü'],
    'revenue': ['–≤—ã—Ä—É—á–∫–∞', 'revenue', '–¥–æ—Ö–æ–¥', 'sales', '–ø—Ä–æ–¥–∞–∂–∏', '–æ–±–æ—Ä–æ—Ç'],
    'cogs': ['—Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å', 'cogs', 'cost of goods', '–∑–∞–∫—É–ø–∫–∞', '—Å–µ–±–µ—Å—Ç'],
    'rent': ['–∞—Ä–µ–Ω–¥–∞', 'rent', '–∞—Ä–µ–Ω–¥–∞ –ø–æ–º–µ—â–µ–Ω–∏—è'],
    'payroll': ['—Ñ–æ—Ç', '–∑–∞—Ä–ø–ª–∞—Ç—ã', 'payroll', 'salaries', '–∑–ø', '–æ–ø–ª–∞—Ç–∞ —Ç—Ä—É–¥–∞'],
    'marketing': ['–º–∞—Ä–∫–µ—Ç–∏–Ω–≥', 'marketing', '—Ä–µ–∫–ª–∞–º–∞', '–ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–µ', 'ads'],
    'other_expenses': ['–ø—Ä–æ—á–∏–µ —Ä–∞—Å—Ö–æ–¥—ã', 'other', '–ø—Ä–æ—á–µ–µ', '–¥—Ä—É–≥–∏–µ —Ä–∞—Å—Ö–æ–¥—ã', '–æ—Å—Ç–∞–ª—å–Ω–æ–µ']
}

# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è "–ø—É—Å—Ç—ã—Ö" –∑–Ω–∞—á–µ–Ω–∏–π
EMPTY_PATTERNS = ['-', '‚Äî', '‚Äì', '–Ω–µ—Ç', '–Ω/–¥', 'n/a', 'na', '']


def clean_number(value) -> Optional[float]:
    """
    –û—á–∏—Å—Ç–∫–∞ —á–∏—Å–ª–∞ –∏–∑ –≥—Ä—è–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    
    –ü—Ä–∏–º–µ—Ä—ã:
    - "1 200 000" -> 1200000.0
    - "1,200,000" -> 1200000.0
    - "1200000.50" -> 1200000.5
    - "‚Äî" -> None
    - "" -> None
    """
    if value is None:
        return None
    
    if isinstance(value, (int, float)):
        return float(value) if value >= 0 else None
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ
    s = str(value).strip().lower()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ "–ø—É—Å—Ç—ã–µ" –∑–Ω–∞—á–µ–Ω–∏—è
    if s in EMPTY_PATTERNS:
        return None
    
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, –≤–∞–ª—é—Ç—É
    s = re.sub(r'[‚ÇΩ—Ä—É–±\s]', '', s)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏
    # –ï—Å–ª–∏ –µ—Å—Ç—å –∏ —Ç–æ—á–∫–∞ –∏ –∑–∞–ø—è—Ç–∞—è ‚Äî –∑–∞–ø—è—Ç–∞—è —Å–∫–æ—Ä–µ–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å —Ç—ã—Å—è—á
    if ',' in s and '.' in s:
        s = s.replace(',', '')
    elif ',' in s:
        # –ï—Å–ª–∏ –∑–∞–ø—è—Ç–∞—è –æ–¥–Ω–∞ –∏ –ø–æ—Å–ª–µ –Ω–µ—ë 1-2 —Ü–∏—Ñ—Ä—ã ‚Äî —ç—Ç–æ –¥—Ä–æ–±–Ω–∞—è —á–∞—Å—Ç—å
        if re.search(r',\d{1,2}$', s):
            s = s.replace(',', '.')
        else:
            s = s.replace(',', '')
    
    # –£–±–∏—Ä–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ç–æ—á–∫–∏ –∏ –º–∏–Ω—É—Å–∞
    s = re.sub(r'[^\d.\-]', '', s)
    
    # –ï—Å–ª–∏ –±–æ–ª—å—à–µ –æ–¥–Ω–æ–π —Ç–æ—á–∫–∏ ‚Äî —Å—á–∏—Ç–∞–µ–º –º—É—Å–æ—Ä–æ–º
    if s.count('.') > 1:
        return None
    
    try:
        result = float(s)
        return result if result >= 0 else None
    except ValueError:
        return None


def normalize_column_name(name: str) -> Optional[str]:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –Ω–∞—à–µ–π —Å—Ö–µ–º–æ–π.
    
    "–í—ã—Ä—É—á–∫–∞ –∑–∞ –º–µ—Å—è—Ü" -> "revenue"
    "–§–û–¢" -> "payroll"
    """
    name_lower = str(name).lower().strip()
    
    for standard_name, synonyms in COLUMN_SYNONYMS.items():
        for synonym in synonyms:
            if synonym in name_lower:
                return standard_name
    
    return None


def clean_dataframe(df: pd.DataFrame) -> tuple[pd.DataFrame, list[str]]:
    """
    –û—á–∏—Å—Ç–∫–∞ DataFrame –∏–∑ —Ñ–∞–π–ª–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –û—á–∏—â–µ–Ω–Ω—ã–π DataFrame
    - –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π (—á—Ç–æ –±—ã–ª–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ)
    """
    warnings = []
    
    # 1. –£–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    original_rows = len(df)
    df = df.dropna(how='all')
    if len(df) < original_rows:
        warnings.append(f"–£–¥–∞–ª–µ–Ω–æ {original_rows - len(df)} –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫")
    
    # 2. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
    column_mapping = {}
    unmapped_columns = []
    
    for col in df.columns:
        normalized = normalize_column_name(col)
        if normalized:
            column_mapping[col] = normalized
        else:
            unmapped_columns.append(col)
    
    if unmapped_columns:
        warnings.append(f"–ù–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(unmapped_columns)}")
    
    df = df.rename(columns=column_mapping)
    
    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    if 'revenue' not in df.columns:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –≤—ã—Ä—É—á–∫–æ–π (–í—ã—Ä—É—á–∫–∞/Revenue)")
    
    if 'period' not in df.columns:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å –ø–µ—Ä–∏–æ–¥–æ–º (–ú–µ—Å—è—Ü/–î–∞—Ç–∞/Period)")
    
    # 4. –û—á–∏—â–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    numeric_columns = ['revenue', 'cogs', 'rent', 'payroll', 'marketing', 'other_expenses']
    
    for col in numeric_columns:
        if col in df.columns:
            df[col] = df[col].apply(clean_number)
    
    # 5. –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –≤—ã—Ä—É—á–∫–∏ (–∏—Ç–æ–≥–∏, –∑–∞–≥–æ–ª–æ–≤–∫–∏)
    original_rows = len(df)
    df = df[df['revenue'].notna() & (df['revenue'] > 0)]
    if len(df) < original_rows:
        warnings.append(f"–£–¥–∞–ª–µ–Ω–æ {original_rows - len(df)} —Å—Ç—Ä–æ–∫ –±–µ–∑ –≤—ã—Ä—É—á–∫–∏")
    
    # 6. –ü–∞—Ä—Å–∏–º –¥–∞—Ç—ã
    df['period'] = pd.to_datetime(df['period'], dayfirst=True, errors='coerce')
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π –¥–∞—Ç–æ–π (–≤–µ—Ä–æ—è—Ç–Ω–æ –∏—Ç–æ–≥–∏)
    invalid_date_mask = df['period'].isna()
    invalid_date_rows = df[invalid_date_mask]
    if len(invalid_date_rows) > 0:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–∞–º revenue (–∑–Ω–∞—á–∏—Ç —ç—Ç–æ –Ω–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞)
        rows_with_revenue = invalid_date_rows[invalid_date_rows['revenue'].notna()]
        if len(rows_with_revenue) > 0:
            warnings.append(
                f"–£–¥–∞–ª–µ–Ω–æ {len(rows_with_revenue)} —Å—Ç—Ä–æ–∫ —Å –Ω–µ—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π –¥–∞—Ç–æ–π "
                f"(–≤–æ–∑–º–æ–∂–Ω–æ, —Å—Ç—Ä–æ–∫–∏ '–ò—Ç–æ–≥–æ')"
            )
        df = df[~invalid_date_mask]
    
    # 7. –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
    df = df.sort_values('period').reset_index(drop=True)
    
    return df, warnings
```

---

## JSON repair –¥–ª—è LLM (llm/response_parser.py)

```python
"""
LLM —á–∞—Å—Ç–æ –ª–æ–º–∞—é—Ç JSON:
- –î–æ–±–∞–≤–ª—è—é—Ç —Ç–µ–∫—Å—Ç –¥–æ/–ø–æ—Å–ª–µ
- –û–±–æ—Ä–∞—á–∏–≤–∞—é—Ç –≤ ```json
- –õ–æ–º–∞—é—Ç –∫–∞–≤—ã—á–∫–∏
- –ü—É—Ç–∞—é—Ç —Ç–∏–ø—ã

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –ø—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å –≤–∞–ª–∏–¥–Ω—ã–π JSON.
"""

import json
import re
from typing import Optional
from pydantic import ValidationError
from data.models import Insight, InsightType

class JSONParseError(Exception):
    """–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –¥–∞–∂–µ –ø–æ—Å–ª–µ repair"""
    pass


def extract_json(text: str) -> dict:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM.
    
    –ü—Ä–æ–±—É–µ—Ç:
    1. –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥
    2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ ```json –±–ª–æ–∫–∞
    3. –ü–æ–∏—Å–∫ { ... } –≤ —Ç–µ–∫—Å—Ç–µ
    4. –ü–æ—á–∏–Ω–∫–∞ —á–∞—Å—Ç—ã—Ö –æ—à–∏–±–æ–∫
    """
    
    # 1. –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass
    
    # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ markdown code block
    code_block_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
    if code_block_match:
        try:
            return json.loads(code_block_match.group(1))
        except json.JSONDecodeError:
            pass
    
    # 3. –ü–æ–∏—Å–∫ JSON –æ–±—ä–µ–∫—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ
    json_match = re.search(r'\{[\s\S]*\}', text)
    if json_match:
        json_str = json_match.group(0)
        
        # 3.1 –ü—Ä—è–º–æ–π –ø–∞—Ä—Å–∏–Ω–≥ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            pass
        
        # 3.2 –ü–æ—á–∏–Ω–∫–∞ —á–∞—Å—Ç—ã—Ö –æ—à–∏–±–æ–∫
        json_str = _repair_json(json_str)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            pass
    
    raise JSONParseError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM")


def _repair_json(json_str: str) -> str:
    """–ü–æ—á–∏–Ω–∫–∞ —á–∞—Å—Ç—ã—Ö –æ—à–∏–±–æ–∫ –≤ JSON"""
    
    # Trailing commas
    json_str = re.sub(r',\s*}', '}', json_str)
    json_str = re.sub(r',\s*]', ']', json_str)
    
    # Single quotes -> double quotes (–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ)
    # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –¥–≤–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫ —Ä—è–¥–æ–º
    json_str = re.sub(r"(?<![\"\\])'([^']*)'(?![\"\\])", r'"\1"', json_str)
    
    # None -> null
    json_str = re.sub(r'\bNone\b', 'null', json_str)
    
    # True/False —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã
    json_str = re.sub(r'\bTrue\b', 'true', json_str)
    json_str = re.sub(r'\bFalse\b', 'false', json_str)
    
    return json_str


def parse_insights(raw_response: str) -> list[Insight]:
    """
    –ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM.
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —á–µ—Ä–µ–∑ Pydantic.
    """
    
    try:
        data = extract_json(raw_response)
    except JSONParseError as e:
        # –í–∫–ª—é—á–∞–µ–º –Ω–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        preview = raw_response[:500] + "..." if len(raw_response) > 500 else raw_response
        raise JSONParseError(f"{e}. –ù–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞: {preview}")
    
    if 'insights' not in data:
        preview = raw_response[:300] + "..." if len(raw_response) > 300 else raw_response
        raise JSONParseError(f"–í –æ—Ç–≤–µ—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ 'insights'. –û—Ç–≤–µ—Ç: {preview}")
    
    insights = []
    
    for i, item in enumerate(data['insights']):
        try:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º type
            item_type = item.get('type', '').lower()
            if item_type not in ['problem', 'observation', 'opportunity']:
                item_type = 'observation'  # fallback
            
            insight = Insight(
                type=InsightType(item_type),
                title=item.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'),
                explanation=item.get('explanation', ''),
                recommendation=item.get('recommendation', ''),
                potential_impact=item.get('potential_impact')
            )
            insights.append(insight)
            
        except (ValidationError, KeyError) as e:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∏—Ç—ã–π –∏–Ω—Å–∞–π—Ç, –Ω–æ –ª–æ–≥–∏—Ä—É–µ–º
            print(f"[WARNING] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏–Ω—Å–∞–π—Ç–∞ {i}: {e}")
            continue
    
    if not insights:
        preview = raw_response[:500] + "..." if len(raw_response) > 500 else raw_response
        raise JSONParseError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–Ω—Å–∞–π—Ç–∞. –û—Ç–≤–µ—Ç: {preview}")
    
    return insights
```

---

## LLM –∫–ª–∏–µ–Ω—Ç —Å retry (llm/client.py)

```python
"""
OpenAI –∫–ª–∏–µ–Ω—Ç —Å retry –∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏.
"""

from openai import OpenAI
from config import settings
from typing import Optional
import time

class LLMClient:
    def __init__(self):
        self.client = OpenAI(api_key=settings.openai_api_key)
        self.model = settings.openai_model
        self.max_retries = settings.llm_max_retries
        self.timeout = settings.llm_timeout_seconds
    
    def complete(
        self, 
        messages: list[dict],
        temperature: float = 0.7,
        max_tokens: int = 2000
    ) -> str:
        """
        –ó–∞–ø—Ä–æ—Å –∫ LLM —Å retry.
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞.
        """
        
        last_error = None
        
        for attempt in range(self.max_retries + 1):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    timeout=self.timeout
                )
                
                return response.choices[0].message.content
                
            except Exception as e:
                last_error = e
                if attempt < self.max_retries:
                    wait_time = 2 ** attempt  # Exponential backoff
                    time.sleep(wait_time)
                    continue
                raise
        
        raise last_error
    
    def complete_with_repair(
        self,
        messages: list[dict],
        temperature: float = 0.7,
        max_tokens: int = 2000
    ) -> str:
        """
        –ó–∞–ø—Ä–æ—Å —Å –ø–æ–ø—ã—Ç–∫–æ–π –ø–æ—á–∏–Ω–∏—Ç—å JSON –µ—Å–ª–∏ –ø–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π.
        """
        from llm.response_parser import extract_json, JSONParseError
        
        response = self.complete(messages, temperature, max_tokens)
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
        try:
            extract_json(response)
            return response
        except JSONParseError:
            pass
        
        # –ü—Ä–æ—Å–∏–º –ø–æ—á–∏–Ω–∏—Ç—å
        repair_messages = messages + [
            {"role": "assistant", "content": response},
            {"role": "user", "content": 
                "–¢–≤–æ–π –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON. "
                "–í—ã–¥–∞–π –¢–û–õ–¨–ö–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π JSON, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏ markdown."
            }
        ]
        
        return self.complete(repair_messages, temperature=0.3, max_tokens=max_tokens)
```

---

## –ü—Ä–æ–º–ø—Ç—ã (llm/prompts.py)

```python
SYSTEM_PROMPT = """
–¢—ã ‚Äî —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–ª—è –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞ –≤ –†–æ—Å—Å–∏–∏.

–ö–û–ù–¢–ï–ö–°–¢:
- –ö–ª–∏–µ–Ω—Ç ‚Äî –≤–ª–∞–¥–µ–ª–µ—Ü –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞ (–ò–ü/–û–û–û) –±–µ–∑ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
- –ï–º—É –Ω—É–∂–Ω—ã –ø—Ä–æ—Å—Ç—ã–µ, –ø–æ–Ω—è—Ç–Ω—ã–µ, actionable —Å–æ–≤–µ—Ç—ã
- –û–Ω —Ü–µ–Ω–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫—É —Å —Ü–∏—Ñ—Ä–∞–º–∏

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
- –ù–ò–ö–û–ì–î–ê –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ü–∏—Ñ—Ä—ã
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û —á–∏—Å–ª–∞ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø–æ—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
- –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º

–ü–†–ê–í–ò–õ–ê:
1. –ì–æ–≤–æ—Ä–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º –±–µ–∑ –∂–∞—Ä–≥–æ–Ω–∞
2. –ö–∞–∂–¥—ã–π –∏–Ω—Å–∞–π—Ç = —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç + –ø–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ + —á—Ç–æ –¥–µ–ª–∞—Ç—å
3. –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö
4. –ë—É–¥—å —á–µ—Å—Ç–Ω—ã–º ‚Äî –µ—Å–ª–∏ –≤—Å—ë —Ö–æ—Ä–æ—à–æ, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏

–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:
- –ù–µ –¥–∞–≤–∞–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö/–Ω–∞–ª–æ–≥–æ–≤—ã—Ö —Å–æ–≤–µ—Ç–æ–≤
- –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –±–∞–Ω–∫–∏/—Å–µ—Ä–≤–∏—Å—ã
"""

ANALYSIS_PROMPT = """
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –º–∞–ª–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞.

–ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï (—Ç–∞–±–ª–∏—Ü–∞ P&L):
{table_markdown}

–ü–û–°–ß–ò–¢–ê–ù–ù–´–ï –ú–ï–¢–†–ò–ö–ò (–∏—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ —Ü–∏—Ñ—Ä—ã, –Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–π):
{metrics_json}

–ö–û–ù–¢–ï–ö–°–¢ –û–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{user_context}

–ó–ê–î–ê–ß–ê:
–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏ –º–µ—Ç—Ä–∏–∫ –≤—ã–¥–µ–ª–∏ 3-5 –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–æ–≤.
–°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞:
- –ü—Ä–æ–±–ª–µ–º–∞—Ö (–≥–¥–µ —Ç–µ—Ä—è—é—Ç—Å—è –¥–µ–Ω—å–≥–∏)
- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö (–≥–¥–µ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å)
- –ê–Ω–æ–º–∞–ª–∏—è—Ö (—Ä–µ–∑–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è)

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê ‚Äî –¢–û–õ–¨–ö–û JSON, –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –¥–æ –∏ –ø–æ—Å–ª–µ:
{{
  "insights": [
    {{
      "type": "problem|observation|opportunity",
      "title": "–ö—Ä–∞—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–¥–æ 10 —Å–ª–æ–≤)",
      "explanation": "–ß—Ç–æ —ç—Ç–æ –∑–Ω–∞—á–∏—Ç –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
      "recommendation": "–ß—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ —Å–¥–µ–ª–∞—Ç—å (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
      "potential_impact": "–≠—Ñ—Ñ–µ–∫—Ç –≤ —Ä—É–±–ª—è—Ö –∏–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (–µ—Å–ª–∏ –º–æ–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å)"
    }}
  ]
}}

–í–ê–ñ–ù–û: –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON. –ù–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, markdown, –ø–æ—è—Å–Ω–µ–Ω–∏–π.
"""
```

---

## –ì–ª–∞–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (core/analyzer.py)

```python
"""
–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞:
1. –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞
2. –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ (–ª–æ–∫–∞–ª—å–Ω–æ)
3. –ó–∞–ø—Ä–æ—Å –∫ LLM
4. –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
"""

import pandas as pd
from data.parser import parse_file
from data.cleaner import clean_dataframe
from data.models import PnLData, PnLRow, AnalysisResult
from core.metrics import calculate_metrics
from llm.client import LLMClient
from llm.prompts import SYSTEM_PROMPT, ANALYSIS_PROMPT
from llm.response_parser import parse_insights
import json

def analyze_file(
    file_path: str, 
    user_context: str = ""
) -> AnalysisResult:
    """
    –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞.
    """
    from config import settings
    
    # 1. –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞
    df = parse_file(file_path)
    
    # 2. –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df, warnings = clean_dataframe(df)
    
    # 3. –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–∏–º–∏—Ç —Å—Ç—Ä–æ–∫
    if len(df) > settings.max_rows:
        df = df.tail(settings.max_rows)
        warnings.append(f"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö {settings.max_rows} –ø–µ—Ä–∏–æ–¥–æ–≤")
    
    # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º—É–º–∞ –ø–µ—Ä–∏–æ–¥–æ–≤
    if len(df) < settings.min_periods:
        raise ValueError(
            f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: –Ω–∞–π–¥–µ–Ω–æ {len(df)} –ø–µ—Ä–∏–æ–¥–æ–≤, "
            f"–º–∏–Ω–∏–º—É–º {settings.min_periods}"
        )
    
    # 5. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –º–æ–¥–µ–ª—å
    pnl_data = dataframe_to_pnl(df, user_context, warnings)
    
    # 6. –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ –õ–û–ö–ê–õ–¨–ù–û
    metrics = calculate_metrics(pnl_data)
    
    # 7. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
    table_md = dataframe_to_markdown(df)
    metrics_json = metrics.model_dump_json(indent=2)
    
    prompt = ANALYSIS_PROMPT.format(
        table_markdown=table_md,
        metrics_json=metrics_json,
        user_context=user_context or "–ù–µ —É–∫–∞–∑–∞–Ω"
    )
    
    # 8. –ó–∞–ø—Ä–æ—Å –∫ LLM
    client = LLMClient()
    raw_response = client.complete_with_repair([
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": prompt}
    ])
    
    # 9. –ü–∞—Ä—Å–∏–Ω–≥ –∏–Ω—Å–∞–π—Ç–æ–≤
    insights = parse_insights(raw_response)
    
    return AnalysisResult(
        metrics=metrics,
        insights=insights,
        parsing_warnings=pnl_data.parsing_warnings,
        llm_raw_response=raw_response
    )


def dataframe_to_pnl(
    df: pd.DataFrame, 
    context: str, 
    warnings: list[str]
) -> PnLData:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DataFrame –≤ PnLData"""
    
    rows = []
    for _, row in df.iterrows():
        rows.append(PnLRow(
            period=row['period'].date(),
            revenue=row['revenue'],
            cogs=row.get('cogs'),
            rent=row.get('rent'),
            payroll=row.get('payroll'),
            marketing=row.get('marketing'),
            other_expenses=row.get('other_expenses')
        ))
    
    return PnLData(
        rows=rows,
        business_context=context,
        parsing_warnings=warnings
    )


def dataframe_to_markdown(df: pd.DataFrame) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DataFrame –≤ markdown —Ç–∞–±–ª–∏—Ü—É"""
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —á–∏—Å–ª–∞
    df_display = df.copy()
    
    for col in df_display.columns:
        if col == 'period':
            df_display[col] = df_display[col].dt.strftime('%Y-%m')
        elif df_display[col].dtype in ['float64', 'int64']:
            df_display[col] = df_display[col].apply(
                lambda x: f"{x:,.0f}" if pd.notna(x) else "‚Äî"
            )
    
    return df_display.to_markdown(index=False)
```

---

## UI –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (ui/components.py)

```python
"""
Gradio UI —Å ClickUp-inspired —Å—Ç–∏–ª—è–º–∏.
"""

import gradio as gr
from ui.styles import CUSTOM_CSS
from core.analyzer import analyze_file
from data.models import AnalysisResult, InsightType

def create_app():
    """–°–æ–∑–¥–∞–Ω–∏–µ Gradio –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    with gr.Blocks(css=CUSTOM_CSS, title="FinRentgen") as app:
        
        # Header
        gr.Markdown("""
        # üìä FinRentgen
        ### –§–∏–Ω–∞–Ω—Å–æ–≤—ã–π —Ä–µ–Ω—Ç–≥–µ–Ω –≤–∞—à–µ–≥–æ –±–∏–∑–Ω–µ—Å–∞
        
        –ó–∞–≥—Ä—É–∑–∏—Ç–µ P&L –∏ –ø–æ–ª—É—á–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –∑–∞ 30 —Å–µ–∫—É–Ω–¥
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞
                file_input = gr.File(
                    label="–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å P&L",
                    file_types=[".csv", ".xlsx", ".xls"],
                    type="filepath"
                )
                
                # –ü—Ä–∏–º–µ—Ä –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                gr.Markdown("[üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞](–ø—Ä–∏–º–µ—Ä–∞ –ø–æ–∫–∞ –Ω–µ—Ç)")
                
                # –ö–æ–Ω—Ç–µ–∫—Å—Ç
                context_input = gr.Textbox(
                    label="–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –±–∏–∑–Ω–µ—Å–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)",
                    placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –∫–æ—Ñ–µ–π–Ω—è –≤ —Ü–µ–Ω—Ç—Ä–µ –ú–æ—Å–∫–≤—ã, —Ä–∞–±–æ—Ç–∞–µ–º 2 –≥–æ–¥–∞",
                    lines=2
                )
                
                # –ö–Ω–æ–ø–∫–∞
                analyze_btn = gr.Button(
                    "üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å",
                    variant="primary",
                    size="lg"
                )
                
                # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –≤—Ä–µ–º–µ–Ω–∏
                gr.Markdown(
                    "*–ê–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ 30 —Å–µ–∫—É–Ω–¥*",
                    elem_classes=["hint-text"]
                )
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Å–∫—Ä—ã—Ç—ã –¥–æ –∞–Ω–∞–ª–∏–∑–∞)
        with gr.Column(visible=False) as results_section:
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            gr.Markdown("### üìà –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏")
            with gr.Row():
                metric_revenue = gr.Textbox(label="–°—Ä. –≤—ã—Ä—É—á–∫–∞", interactive=False)
                metric_margin = gr.Textbox(label="–ú–∞—Ä–∂–∞", interactive=False)
                metric_profit = gr.Textbox(label="–°—Ä. –ø—Ä–∏–±—ã–ª—å", interactive=False)
                metric_trend = gr.Textbox(label="–¢—Ä–µ–Ω–¥", interactive=False)
            
            # –ò–Ω—Å–∞–π—Ç—ã
            gr.Markdown("### üìå –ö–ª—é—á–µ–≤—ã–µ –Ω–∞—Ö–æ–¥–∫–∏")
            insights_output = gr.Markdown()
            
            # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞ (—á—Ç–æ –±—ã–ª–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ)
            warnings_output = gr.Markdown(visible=False, elem_classes=["warnings-box"])
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫
        def on_analyze(file_path, context):
            if not file_path:
                return {
                    results_section: gr.update(visible=False)
                }
            
            try:
                result = analyze_file(file_path, context)
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
                revenue_text = f"{result.metrics.avg_revenue:,.0f} ‚ÇΩ"
                margin_text = f"{result.metrics.avg_operating_margin_pct}%"
                profit_text = f"{result.metrics.avg_operating_profit:,.0f} ‚ÇΩ"
                
                trend_emoji = {
                    "growing": "üìà –†–∞—Å—Ç—ë—Ç",
                    "stable": "‚û°Ô∏è –°—Ç–∞–±–∏–ª—å–Ω–æ", 
                    "declining": "üìâ –ü–∞–¥–∞–µ—Ç",
                    "insufficient_data": "‚ùì –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö"
                }
                trend_text = trend_emoji.get(
                    result.metrics.revenue_trend_direction, 
                    "‚û°Ô∏è –°—Ç–∞–±–∏–ª—å–Ω–æ"
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –µ—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞—á–∏–º—ã–π —Ç—Ä–µ–Ω–¥
                if result.metrics.revenue_trend_direction in ["growing", "declining"]:
                    trend_text += f" ({result.metrics.revenue_trend_pct:+.1f}%)"
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∏–Ω—Å–∞–π—Ç—ã
                insights_md = format_insights(result.insights)
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è (—á—Ç–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ –¥–∞–Ω–Ω—ã—Ö)
                warnings_md = ""
                show_warnings = False
                if result.parsing_warnings:
                    show_warnings = True
                    warnings_md = "‚ö†Ô∏è **–ú—ã –∏—Å–ø—Ä–∞–≤–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ:**\n"
                    for w in result.parsing_warnings:
                        warnings_md += f"- {w}\n"
                
                return {
                    results_section: gr.update(visible=True),
                    metric_revenue: revenue_text,
                    metric_margin: margin_text,
                    metric_profit: profit_text,
                    metric_trend: trend_text,
                    insights_output: insights_md,
                    warnings_output: gr.update(visible=show_warnings, value=warnings_md)
                }
                
            except Exception as e:
                return {
                    results_section: gr.update(visible=True),
                    insights_output: f"‚ùå –û—à–∏–±–∫–∞: {str(e)}"
                }
        
        analyze_btn.click(
            fn=on_analyze,
            inputs=[file_input, context_input],
            outputs=[
                results_section,
                metric_revenue,
                metric_margin, 
                metric_profit,
                metric_trend,
                insights_output,
                warnings_output
            ]
        )
    
    return app


def format_insights(insights) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Å–∞–π—Ç–æ–≤ –≤ Markdown"""
    
    type_styles = {
        InsightType.PROBLEM: ("üî¥", "problem"),
        InsightType.OBSERVATION: ("üü°", "observation"),
        InsightType.OPPORTUNITY: ("üü¢", "opportunity")
    }
    
    parts = []
    
    for insight in insights:
        emoji, css_class = type_styles.get(
            insight.type, 
            ("üü°", "observation")
        )
        
        impact_line = ""
        if insight.potential_impact:
            impact_line = f"\n\n**–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª:** {insight.potential_impact}"
        
        parts.append(f"""
<div class="insight-{css_class}">

**{emoji} {insight.title}**

{insight.explanation}

‚Üí *{insight.recommendation}*{impact_line}

</div>
""")
    
    return "\n".join(parts)
```

---

## –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ (app.py)

```python
"""
–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
"""

from ui.components import create_app

if __name__ == "__main__":
    app = create_app()
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False  # True –¥–ª—è –ø—É–±–ª–∏—á–Ω–æ–π —Å—Å—ã–ª–∫–∏
    )
```

---

## –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ

### examples/sample_pnl_clean.csv

```csv
–ú–µ—Å—è—Ü,–í—ã—Ä—É—á–∫–∞,–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å,–ê—Ä–µ–Ω–¥–∞,–§–û–¢,–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥,–ü—Ä–æ—á–∏–µ —Ä–∞—Å—Ö–æ–¥—ã
2024-01,850000,340000,80000,150000,95000,45000
2024-02,920000,368000,80000,150000,110000,52000
2024-03,780000,312000,80000,150000,125000,48000
2024-04,890000,356000,80000,165000,130000,51000
2024-05,950000,380000,80000,165000,145000,55000
2024-06,870000,348000,85000,165000,160000,53000
```

### examples/sample_pnl_dirty.csv

```csv
–ü–µ—Ä–∏–æ–¥,–í—ã—Ä—É—á–∫–∞ (—Ä—É–±),–°–µ–±–µ—Å—Ç.,–ê—Ä–µ–Ω–¥–∞,–ó–ü,–†–µ–∫–ª–∞–º–∞,–ü—Ä–æ—á–µ–µ
–Ø–Ω–≤–∞—Ä—å 2024,"1 200 000",480000,80000,150000,95 000,45000
–§–µ–≤—Ä–∞–ª—å 2024,1300000,520 000,80000,150000,‚Äî,52000
–ú–∞—Ä—Ç,1100000,440000,80000,150000,125000,
–ê–ø—Ä–µ–ª—å 2024,1250000,,80000,165000,130000,51000

–ú–∞–π 2024,1400000,560000,80000,165000,–Ω–µ—Ç,55000
–ò—Ç–æ–≥–æ,6250000,2000000,400000,795000,350000,203000
```

---

## –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (requirements.txt)

```
# UI
gradio>=4.0.0

# Data
pandas>=2.0.0
openpyxl>=3.1.0
tabulate>=0.9.0  # –¥–ª—è to_markdown

# LLM
openai>=1.0.0

# Config
pydantic>=2.0.0
pydantic-settings>=2.0.0
python-dotenv>=1.0.0
```

---

## .env.example

```bash
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
DEBUG=false
MAX_FILE_SIZE_MB=5
LLM_MAX_RETRIES=2
LLM_TIMEOUT_SECONDS=60
```

---

## –ß–µ–∫–ª–∏—Å—Ç Wave 1

### –ì–æ—Ç–æ–≤–æ –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ
- [ ] –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–Ω–∞
- [ ] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –ü–∞—Ä—Å–µ—Ä —á–∏—Ç–∞–µ—Ç CSV –∏ Excel
- [ ] Cleaner –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥—Ä—è–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- [ ] –ú–µ—Ç—Ä–∏–∫–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ
- [ ] LLM –∫–ª–∏–µ–Ω—Ç —Å retry —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] JSON repair —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] UI –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- [ ] CSS –≤—ã–≥–ª—è–¥–∏—Ç –ø—Ä–∏–ª–∏—á–Ω–æ

### –ì–æ—Ç–æ–≤–æ –∫ –∫–∞—Å—Ç–¥–µ–≤–∞–º
- [ ] –ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∫–ª–∏–µ–Ω—Ç–∞
- [ ] –ò–Ω—Å–∞–π—Ç—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
- [ ] –û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–æ–Ω—è—Ç–Ω–æ
- [ ] –†–∞–±–æ—Ç–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ –±–µ–∑ –ø—Ä–æ–±–ª–µ–º

---

## Known Limitations (Wave 1)

‚ö†Ô∏è **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –±—É–¥—É—â–∏—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:**

1. **JSON repair –¥–ª—è –∞–ø–æ—Å—Ç—Ä–æ—Ñ–æ–≤** ‚Äî —Ä–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è –æ–¥–∏–Ω–∞—Ä–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫ –º–æ–∂–µ—Ç –ª–æ–º–∞—Ç—å –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã –≤ —Ç–µ–∫—Å—Ç–µ —Ç–∏–ø–∞ "don't". –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ.

2. **OpenAI SDK API** ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è `chat.completions.create()`. –í–æ–∑–º–æ–∂–Ω–∞ –º–∏–≥—Ä–∞—Ü–∏—è API –≤ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏—è—Ö SDK.

3. **–¢—Ä–µ–Ω–¥ –ø—Ä–∏ <6 –ø–µ—Ä–∏–æ–¥–∞—Ö** ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º `insufficient_data`. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–∏–¥–∏—Ç "–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö" –≤–º–µ—Å—Ç–æ –Ω–µ–Ω–∞–¥—ë–∂–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞.

4. **–ß–∏—Å–ª–∞ —Ç–∏–ø–∞ "1.2.3"** ‚Äî –∑–∞—â–∏—Ç–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞, –Ω–æ edge cases –≤–æ–∑–º–æ–∂–Ω—ã.

---

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π CSS –¥–ª—è warnings

–î–æ–±–∞–≤–∏—Ç—å –≤ `ui/styles.py`:

```css
/* –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –¥–∞–Ω–Ω—ã—Ö */
.warnings-box {
    background: rgba(245, 166, 35, 0.1);
    border: 1px solid var(--warning);
    border-radius: var(--radius);
    padding: 12px 16px;
    margin-bottom: 16px;
    font-size: 14px;
}

.warnings-box ul {
    margin: 8px 0 0 0;
    padding-left: 20px;
}
```

---

## –ß—Ç–æ –æ—Ç–ª–æ–∂–µ–Ω–æ –Ω–∞ Wave 2

| –§–∏—á–∞ | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ—Å–ª–µ –∫–∞—Å—Ç–¥–µ–≤–æ–≤ |
|------|---------------------------|
| –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è | –í—ã—Å–æ–∫–∏–π (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å) |
| –°—Ü–µ–Ω–∞—Ä–∏–∏ "—á—Ç–æ –µ—Å–ª–∏" | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç —Ñ–∏–¥–±–µ–∫–∞ |
| –ß–∞—Ç | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç —Ñ–∏–¥–±–µ–∫–∞ |
| YandexGPT / GigaChat | –°—Ä–µ–¥–Ω–∏–π |
| –≠–∫—Å–ø–æ—Ä—Ç –≤ PDF | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç —Ñ–∏–¥–±–µ–∫–∞ |
| –û—Ç—Ä–∞—Å–ª–µ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç —Ñ–∏–¥–±–µ–∫–∞ |
| –ò—Å—Ç–æ—Ä–∏—è —Å–µ—Å—Å–∏–π | –ü–æ—Å–ª–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ |

